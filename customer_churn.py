# -*- coding: utf-8 -*-
"""Customer_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bJmA-lG1AMZJy75UolIXggLa_EIGWFRc
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('/content/E Commerce Dataset (1).csv')
print(df)

"""# New Section"""

print(df.shape)
df.head()

percent_missing = df.isnull().sum() * 100 / len(df)
missing_value_df = pd.DataFrame({'column_name': df.columns,
                                 'percent_missing': round(percent_missing,1)})
missing_value_df = missing_value_df.sort_values('percent_missing', ascending=True)
plt.figure(figsize=(5,5))
plt.barh(missing_value_df['column_name'],missing_value_df['percent_missing'])
plt.tick_params(axis='y', which='both',length=0)
plt.title('Percentage of Missing Data')

df['PreferredPaymentMode'].unique()

df['PreferredPaymentMode'] = df['PreferredPaymentMode'].str.replace('Cash on Delivery','COD')
df['PreferredPaymentMode'] = df['PreferredPaymentMode'].str.replace('Credit Card','CC')

binary_cat_cols = ['Complain']
outcome = ['Churn']
cat_cols = ['PreferredLoginDevice','Gender','PreferedOrderCat','MaritalStatus','CityTier']
num_cols = ['Tenure','WarehouseToHome','HourSpendOnApp','NumberOfDeviceRegistered','SatisfactionScore','NumberOfAddress','OrderAmountHikeFromlastYear',
           'CouponUsed','OrderCount','DaySinceLastOrder','CashbackAmount']

import seaborn as sns
fig, ax = plt.subplots(3,4,figsize=(20, 18))
fig.suptitle('Distribution of Numeric Features by Churn', fontsize=20)
ax = ax.flatten()
for idx,c in enumerate(num_cols):
    df_t = df[df[c].notnull()].copy()
    ax[idx].set_title(c)
    sns.boxplot(x='Churn', y=c, data=df_t, ax=ax[idx])
    ax[idx].set_ylabel('')
plt.show()

fig, ax = plt.subplots(3,2,figsize=(20, 15))
fig.suptitle('Churn Percentage by Categorical Features', fontsize=20)
ax = ax.flatten()

for idx,c in enumerate(cat_cols+binary_cat_cols):
    df.groupby(c).Churn.mean().plot.barh(ax=ax[idx])
    ax[idx].set_xlabel('Churn Percentage')
plt.show()

df[num_cols] = df[num_cols].fillna(df[num_cols].median())

df_c = df[df['Churn']==1].copy()
df_nc = df[df['Churn']==0].copy()

fig, ax = plt.subplots(3,4,figsize=(20, 18))
fig.suptitle('Density of Numeric Features by Churn', fontsize=20)
ax = ax.flatten()

for idx,c in enumerate(num_cols):
    sns.kdeplot(df_c[c], linewidth= 3,
             label = 'Churn',ax=ax[idx])
    sns.kdeplot(df_nc[c], linewidth= 3,
             label = 'No Churn',ax=ax[idx])

    ax[idx].legend(loc='upper right')

plt.show()

df[num_cols] = df[num_cols].fillna(df[num_cols].median())

def remove_outlier(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR=Q3-Q1
    lr= Q1-(1.5 * IQR)
    ur= Q3+(1.5 * IQR)

    df[col]=np.where(df[col]>ur,ur,df[col])
    df[col]=np.where(df[col]<lr,lr,df[col])

    return df

for c in num_cols:
    df = remove_outlier(df, c)

df = df.replace(' ', '_', regex=True)
df = df.replace('&', 'And', regex=True)

df_encoded = pd.get_dummies(df,drop_first=True)
df_encoded.columns

from sklearn.model_selection import train_test_split, cross_val_score
x = df_encoded[['Tenure', 'CityTier', 'WarehouseToHome',
       'HourSpendOnApp', 'NumberOfDeviceRegistered', 'SatisfactionScore',
       'NumberOfAddress', 'Complain', 'OrderAmountHikeFromlastYear',
       'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount',
       'PreferredLoginDevice_Mobile_Phone', 'PreferredLoginDevice_Phone',
       'PreferredPaymentMode_COD', 'PreferredPaymentMode_Debit_Card',
       'PreferredPaymentMode_E_wallet', 'PreferredPaymentMode_UPI',
       'Gender_Male', 'PreferedOrderCat_Grocery',
       'PreferedOrderCat_Laptop_And_Accessory', 'PreferedOrderCat_Mobile',
       'PreferedOrderCat_Mobile_Phone', 'PreferedOrderCat_Others',
       'MaritalStatus_Married', 'MaritalStatus_Single']].copy()
y = df_encoded['Churn']
x_train, x_test, y_train, y_test = train_test_split(x,y, train_size = 0.8, random_state=42)

from sklearn.preprocessing import MinMaxScaler
norm = MinMaxScaler().fit(x_train)
x_train_norm = norm.transform(x_train)
x_test_norm = norm.transform(x_test)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(x_train, y_train)

from sklearn.metrics import classification_report
lr = LogisticRegression(random_state=42)
lr.fit(x_train, y_train)
lr_probs = lr.predict_proba(x_test)

print(type(lr))
scores = cross_val_score(lr,x_train,y_train,cv=5,scoring='roc_auc')
print ("CV score :",scores.mean())
lr.fit(x_train, y_train)
pred = lr.predict(x_test)
print(classification_report(y_test, pred))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, pred)

sns.heatmap(cm,
            annot=True,
            fmt='g')
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import classification_report
scores = cross_val_score(classifier,x_train,y_train,cv=5,scoring='roc_auc')
print ("CV score :",scores.mean())
classifier.fit(x_train, y_train)
pred = classifier.predict(x_test)
print(classification_report(y_test, pred))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, pred)
sns.heatmap(cm,
            annot=True,
            fmt='g')
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()